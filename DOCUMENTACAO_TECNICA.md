# ğŸ“– DocumentaÃ§Ã£o TÃ©cnica - FlertAI v3

## ğŸ¯ VisÃ£o Geral

**FlertAI** Ã© uma aplicaÃ§Ã£o Flutter para geraÃ§Ã£o inteligente de mensagens de paquera, utilizando IA multimodal (GPT-4o Vision) com anÃ¡lise de screenshots de conversas e perfis.

### **VersÃ£o:** 3.0.0 (Pipeline Multimodal One-Shot)
### **Status:** âœ… Pronto para ProduÃ§Ã£o
### **Ãšltima AtualizaÃ§Ã£o:** 03/10/2025

---

## ğŸ—ï¸ Arquitetura

### **Stack TecnolÃ³gico**

#### **Frontend:**
- **Framework:** Flutter 3.16.0+
- **Linguagem:** Dart 3.1.0+
- **State Management:** Flutter BLoC 8.1.3
- **Plataformas:** Web, Android, iOS

#### **Backend:**
- **BaaS:** Supabase
- **Edge Functions:** Deno (TypeScript)
- **Banco de Dados:** PostgreSQL
- **Storage:** Supabase Storage
- **Auth:** Supabase Auth

#### **IA/ML:**
- **Modelo Principal:** OpenAI GPT-4o (via Edge Functions)
- **OCR Mobile:** Google ML Kit Text Recognition
- **OCR Web:** OpenAI Vision API (backend)
- **Processamento de Imagem:** Biblioteca `image` (Dart)

---

## ğŸ“‚ Estrutura do Projeto

```
flerta_ai/
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ apresentacao/           # UI Layer
â”‚   â”‚   â”œâ”€â”€ screens/            # Telas principais
â”‚   â”‚   â””â”€â”€ widgets/            # Widgets reutilizÃ¡veis
â”‚   â”‚       â”œâ”€â”€ context_preview.dart       # Preview do contexto extraÃ­do
â”‚   â”‚       â”œâ”€â”€ custom_app_bar.dart        # AppBar customizado
â”‚   â”‚       â”œâ”€â”€ custom_floating_action_button.dart
â”‚   â”‚       â””â”€â”€ tone_dropdown.dart         # Seletor de tom
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ constants/
â”‚   â”‚       â””â”€â”€ supabase_config.dart       # ConfiguraÃ§Ãµes Supabase
â”‚   â”œâ”€â”€ servicos/               # Services Layer
â”‚   â”‚   â”œâ”€â”€ ai_service.dart     # ServiÃ§o principal de IA
â”‚   â”‚   â”œâ”€â”€ ocr_service.dart    # ServiÃ§o OCR (mobile)
â”‚   â”‚   â””â”€â”€ user_learning_service.dart     # Aprendizado do usuÃ¡rio
â”‚   â”œâ”€â”€ utils/                  # UtilitÃ¡rios
â”‚   â”‚   â””â”€â”€ preprocess_screenshot.dart     # PrÃ©-processamento de imagem
â”‚   â””â”€â”€ main.dart               # Entry point
â”œâ”€â”€ supabase/
â”‚   â”œâ”€â”€ functions/
â”‚   â”‚   â””â”€â”€ analyze-conversation/
â”‚   â”‚       â””â”€â”€ index.ts        # Edge Function principal
â”‚   â””â”€â”€ migrations/
â”‚       â””â”€â”€ 20251003_add_anchors_and_metrics.sql
â”œâ”€â”€ test/                       # Testes
â”œâ”€â”€ build/web/                  # Build de produÃ§Ã£o
â”œâ”€â”€ pubspec.yaml                # DependÃªncias
â””â”€â”€ README.md
```

---

## ğŸ”§ Componentes Principais

### **1. AIService (`lib/servicos/ai_service.dart`)**

**Responsabilidade:** OrquestraÃ§Ã£o de IA e comunicaÃ§Ã£o com backend.

**Funcionalidades:**
- âœ… Upload de imagens para Supabase Storage
- âœ… PrÃ©-processamento automÃ¡tico de imagens
- âœ… ExecuÃ§Ã£o de OCR (mobile)
- âœ… Chamadas Ã  Edge Function de anÃ¡lise
- âœ… Cache de `vision_context` para otimizaÃ§Ã£o
- âœ… Fallback para base64 quando upload falha
- âœ… Singleton pattern

**MÃ©todos Principais:**

```dart
// Upload de imagem com fallback base64
Future<String?> uploadImageToStorage({required String imagePath})

// AnÃ¡lise completa com OCR + Vision
Future<Map<String, dynamic>> analyzeImageAndGenerateSuggestions({
  String? imagePath,
  required String tone,
  List<String>? focusTags,
})

// GeraÃ§Ã£o adicional usando cache
Future<Map<String, dynamic>> generateMoreSuggestions({
  required String imageId,
  required String tone,
  List<String>? previousSuggestions,
})
```

**Exemplo de Uso:**

```dart
final aiService = AIService();

// Fazer upload da imagem
final imagePath = await aiService.uploadImageToStorage(
  imagePath: pickedImage.path,
);

// Analisar e gerar sugestÃ£o
final result = await aiService.analyzeImageAndGenerateSuggestions(
  imagePath: imagePath,
  tone: 'ğŸ˜˜ flertar',
  focusTags: ['hobbies', 'viagem'],
);

print(result['suggestions']); // Lista com 1 sugestÃ£o
```

---

### **2. OCRService (`lib/servicos/ocr_service.dart`)**

**Responsabilidade:** ExtraÃ§Ã£o de texto de imagens (mobile).

**Funcionalidades:**
- âœ… OCR em Android/iOS via Google ML Kit
- âœ… DetecÃ§Ã£o automÃ¡tica de dimensÃµes da imagem
- âœ… Suporte a mÃºltiplos idiomas (Latin script)
- âœ… Logs detalhados para debug
- âœ… Web delegado ao backend

**MÃ©todos Principais:**

```dart
// Extrair texto de bytes de imagem
Future<String> extractText(Uint8List imageBytes)

// Limpeza de recursos
void dispose()
```

**Exemplo de Uso:**

```dart
final ocrService = OCRService();
final imageBytes = await File(imagePath).readAsBytes();
final text = await ocrService.extractText(imageBytes);

print('Texto extraÃ­do: $text');
```

---

### **3. ImagePreprocessor (`lib/utils/preprocess_screenshot.dart`)**

**Responsabilidade:** OtimizaÃ§Ã£o de imagens antes do upload.

**Funcionalidades:**
- âœ… Resize para largura mÃ¡xima de 1280px
- âœ… Crop automÃ¡tico de status bar
- âœ… Ajuste de contraste e gamma
- âœ… CompressÃ£o JPEG 85%
- âœ… ReduÃ§Ã£o de ~30-60% no tamanho do arquivo

**MÃ©todos Principais:**

```dart
// PrÃ©-processar imagem completa
static Future<Uint8List> preprocessImage(Uint8List imageBytes)
```

**Pipeline de Processamento:**

```
Imagem Original
    â†“
1. Decodificar
    â†“
2. Crop Status Bar (se detectada)
    â†“
3. Resize (max 1280px largura)
    â†“
4. Ajuste de Contraste (+20%)
    â†“
5. Ajuste de Gamma (0.9)
    â†“
6. Encode JPEG (85%)
    â†“
Imagem Otimizada
```

---

### **4. ContextPreview Widget (`lib/apresentacao/widgets/context_preview.dart`)**

**Responsabilidade:** Exibir contexto extraÃ­do da imagem.

**Funcionalidades:**
- âœ… Mostra nome detectado
- âœ… Mostra descriÃ§Ã£o visual
- âœ… Mostra texto OCR
- âœ… Estado vazio com mensagem
- âœ… Design responsivo

**Exemplo de Uso:**

```dart
ContextPreview(
  visionContext: {
    'personName': 'Ana',
    'imageDescription': 'Mulher sorrindo na praia',
    'conversationSegments': [...],
  },
)
```

---

### **5. Edge Function (`supabase/functions/analyze-conversation/index.ts`)**

**Responsabilidade:** Processamento backend de IA.

**Funcionalidades:**
- âœ… AnÃ¡lise multimodal (Vision + Text)
- âœ… GeraÃ§Ã£o de 1 sugestÃ£o contextualizada
- âœ… ExtraÃ§Ã£o e validaÃ§Ã£o de Ã¢ncoras
- âœ… Anti-alucinaÃ§Ã£o rigorosa
- âœ… Rate limiting por IP
- âœ… MÃ©tricas de qualidade
- âœ… Cache de vision_context

**Fluxo de Processamento:**

```
1. Receber Request
   â†“
2. Validar Rate Limit
   â†“
3. Processar Imagem (se skip_vision = false)
   â”œâ”€ Chamar GPT-4o Vision
   â””â”€ Extrair nome, descriÃ§Ã£o, OCR
   â†“
4. Extrair Ã‚ncoras
   â”œâ”€ Nome da pessoa
   â”œâ”€ Palavras-chave visuais
   â””â”€ Entidades do texto OCR
   â†“
5. Gerar SugestÃ£o
   â”œâ”€ Prompt anti-alucinaÃ§Ã£o
   â””â”€ Tom personalizado
   â†“
6. Validar Ã‚ncoras
   â”œâ”€ Verificar â‰¥1 Ã¢ncora presente
   â””â”€ Regenerar se invÃ¡lida
   â†“
7. Calcular MÃ©tricas
   â”œâ”€ LatÃªncia
   â”œâ”€ Tokens
   â”œâ”€ Cobertura de Ã¢ncoras
   â””â”€ Taxa de repetiÃ§Ã£o
   â†“
8. Salvar em DB
   â””â”€ generation_metrics
   â†“
9. Retornar Response
```

**Endpoints:**

```typescript
POST /analyze-conversation
Body: {
  image_path?: string,
  image_base64?: string,
  tone: string,
  focus_tags?: string[],
  ocr_text_raw?: string,
  skip_vision?: boolean,
  vision_context?: {...},
  previous_suggestions?: string[]
}

Response: {
  suggestions: string[],
  vision_context: {
    personName: string,
    imageDescription: string,
    conversationSegments: {...}[]
  },
  anchors: string[],
  anchors_used: string[],
  low_confidence: boolean,
  metrics: {...}
}
```

---

## ğŸ—„ï¸ Banco de Dados

### **Tabelas Principais**

#### **1. conversations**
```sql
CREATE TABLE conversations (
  id UUID PRIMARY KEY,
  user_id UUID REFERENCES auth.users,
  image_url TEXT,
  tone TEXT,
  focus_tags TEXT[],
  analysis_result JSONB,  -- Inclui: vision_context, anchors, anchors_used
  created_at TIMESTAMPTZ DEFAULT NOW()
);
```

#### **2. suggestions**
```sql
CREATE TABLE suggestions (
  id UUID PRIMARY KEY,
  conversation_id UUID REFERENCES conversations,
  suggestion_text TEXT,
  was_sent BOOLEAN DEFAULT FALSE,
  created_at TIMESTAMPTZ DEFAULT NOW()
);
```

#### **3. generation_metrics**
```sql
CREATE TABLE generation_metrics (
  id UUID PRIMARY KEY,
  conversation_id UUID REFERENCES conversations,
  suggestion_id UUID REFERENCES suggestions,
  latency_ms INTEGER,
  tokens_input INTEGER,
  tokens_output INTEGER,
  anchors_used INTEGER,
  anchors_total INTEGER,
  repetition_rate NUMERIC,
  low_confidence BOOLEAN,
  created_at TIMESTAMPTZ DEFAULT NOW()
);
```

#### **4. user_learning**
```sql
CREATE TABLE user_learning (
  id UUID PRIMARY KEY,
  user_id UUID REFERENCES auth.users,
  feedback_type TEXT,  -- 'like', 'dislike', 'edit', 'send'
  original_suggestion TEXT,
  modified_suggestion TEXT,
  context JSONB,
  created_at TIMESTAMPTZ DEFAULT NOW()
);
```

#### **5. cultural_references**
```sql
CREATE TABLE cultural_references (
  id UUID PRIMARY KEY,
  reference_type TEXT,  -- 'giria', 'meme', 'musica', etc.
  reference_text TEXT,
  region TEXT,  -- 'sul', 'sudeste', 'nacional', etc.
  created_at TIMESTAMPTZ DEFAULT NOW()
);
```

---

## ğŸ” SeguranÃ§a

### **PrÃ¡ticas Implementadas:**

#### **1. VariÃ¡veis de Ambiente**
```dart
// âŒ ANTES (Inseguro)
static const url = 'https://projeto.supabase.co';

// âœ… AGORA (Seguro)
static String get url => const String.fromEnvironment(
  'SUPABASE_URL',
  defaultValue: '' // Vazio em produÃ§Ã£o
);
```

#### **2. Rate Limiting**
```typescript
// 50 requests por hora por IP (anÃ´nimo)
const RATE_LIMIT = 50;
const WINDOW_MS = 3600000; // 1 hora
```

#### **3. Row Level Security (RLS)**
```sql
-- UsuÃ¡rios sÃ³ acessam suas prÃ³prias conversas
CREATE POLICY "Users can view own conversations"
  ON conversations FOR SELECT
  USING (auth.uid() = user_id);
```

#### **4. Content Security Policy**
```
default-src 'self';
script-src 'self' 'unsafe-inline' 'unsafe-eval';
connect-src 'self' https://*.supabase.co;
```

---

## ğŸ“Š MÃ©tricas de Qualidade

### **Cobertura de Ã‚ncoras**

**Objetivo:** â‰¥95% das mensagens usam pelo menos 1 Ã¢ncora

**CÃ¡lculo:**
```typescript
const coverage = (anchorsUsed / anchorsTotal) * 100;
```

**AÃ§Ãµes se < 95%:**
- Regenerar mensagem
- ReforÃ§ar prompt anti-alucinaÃ§Ã£o
- Marcar `low_confidence = true`

---

### **Taxa de RepetiÃ§Ã£o**

**Objetivo:** <30% similaridade com mensagens anteriores

**CÃ¡lculo:** Similaridade de Jaccard com bigramas
```typescript
const similarity = intersection(bigrams1, bigrams2) / union(bigrams1, bigrams2);
```

---

### **LatÃªncia**

**Metas:**
- **1Âª GeraÃ§Ã£o:** <20s (com Vision API)
- **Gerar Mais:** <5s (com cache)

---

## ğŸ§ª Testes

### **Estrutura de Testes**

```
test/
â”œâ”€â”€ servicos/
â”‚   â”œâ”€â”€ ai_service_test.dart
â”‚   â””â”€â”€ ocr_service_test.dart
â”œâ”€â”€ widgets/
â”‚   â”œâ”€â”€ context_preview_test.dart
â”‚   â””â”€â”€ custom_app_bar_test.dart
â””â”€â”€ utils/
    â””â”€â”€ preprocess_screenshot_test.dart
```

### **Executar Testes**

```bash
# Todos os testes
flutter test

# Testes especÃ­ficos
flutter test test/servicos/ai_service_test.dart

# Com cobertura
flutter test --coverage
```

---

## ğŸš€ Deploy

### **Build de ProduÃ§Ã£o**

```bash
# Web
flutter build web --release

# Android
flutter build apk --release

# iOS
flutter build ios --release
```

### **VerificaÃ§Ã£o de Build**

```bash
# Analisar cÃ³digo
flutter analyze

# Verificar dependÃªncias
flutter doctor -v

# Limpar cache
flutter clean && flutter pub get
```

---

## ğŸ“ˆ Performance

### **OtimizaÃ§Ãµes Implementadas:**

1. **Cache de Vision Context**
   - Evita reprocessamento de imagem
   - Reduz latÃªncia em 75% para "Gerar mais"

2. **PrÃ©-processamento On-Device**
   - Reduz tamanho de upload em 40%
   - Melhora qualidade OCR

3. **Lazy Loading**
   - Widgets carregados sob demanda
   - Reduz tempo de inicializaÃ§Ã£o

4. **Singleton Services**
   - Menos instÃ¢ncias em memÃ³ria
   - Compartilhamento de recursos

---

## ğŸ› Troubleshooting

### **Problema: OCR nÃ£o detecta texto**

**Causa:** Imagem com baixa qualidade ou texto muito pequeno

**SoluÃ§Ã£o:**
1. Verificar prÃ©-processamento ativado
2. Aumentar resoluÃ§Ã£o da imagem
3. Verificar logs: `debugPrint` no OCRService

---

### **Problema: "Too many positional arguments"**

**Causa:** API da biblioteca `image` desatualizada

**SoluÃ§Ã£o:**
```dart
// âŒ ANTES
img.copyCrop(image, x, y, width, height)

// âœ… AGORA
img.copyCrop(image, x: 0, y: 80, width: w, height: h)
```

---

### **Problema: Upload de imagem falha**

**Causa:** PermissÃµes do Supabase Storage

**SoluÃ§Ã£o:**
1. Verificar RLS policies no bucket `images`
2. Usar fallback base64 (jÃ¡ implementado)
3. Verificar tamanho mÃ¡ximo permitido

---

## ğŸ“š ReferÃªncias

- **Flutter:** https://flutter.dev/docs
- **Supabase:** https://supabase.com/docs
- **OpenAI API:** https://platform.openai.com/docs
- **Google ML Kit:** https://developers.google.com/ml-kit
- **Dart Image:** https://pub.dev/packages/image

---

## ğŸ‘¥ Contribuindo

### **Workflow:**

1. Fork o repositÃ³rio
2. Criar branch: `feat/nova-funcionalidade`
3. Commit: `feat: descriÃ§Ã£o da mudanÃ§a`
4. Push e criar Pull Request
5. Aguardar code review

### **PadrÃµes de CÃ³digo:**

- Clean Code principles
- SOLID principles
- Test-Driven Development (TDD)
- Conventional Commits

---

## ğŸ“„ LicenÃ§a

Este projeto Ã© propriedade de **FlertAI** e estÃ¡ sob licenÃ§a proprietÃ¡ria.

---

## ğŸ“ Contato

**Desenvolvedor:** Vanzer80  
**RepositÃ³rio:** https://github.com/vanzer80/flert-ai  
**VersÃ£o:** 3.0.0
