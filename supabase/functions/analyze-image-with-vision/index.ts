import { serve } from 'https://deno.land/std@0.168.0/http/server.ts'
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2'

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
}

serve(async (req) => {
  // Handle CORS preflight
  if (req.method === 'OPTIONS') {
    return new Response('ok', { headers: corsHeaders })
  }

  try {
    const startTime = Date.now()
    console.log('üöÄ Iniciando an√°lise de imagem com GPT-4 Vision...')

    // Parse request
    const { image, tone } = await req.json()
    
    if (!image) {
      throw new Error('Imagem n√£o fornecida')
    }

    console.log('üì∏ Imagem recebida, tamanho:', image.length, 'caracteres')
    console.log('üé® Tom selecionado:', tone)

    // Get OpenAI API key
    const openaiApiKey = Deno.env.get('OPENAI_API_KEY')
    if (!openaiApiKey) {
      throw new Error('OPENAI_API_KEY n√£o configurada')
    }

    console.log('üîë OpenAI API Key configurada:', openaiApiKey.substring(0, 10) + '...')

    // 1. Analisar imagem com GPT-4 Vision
    console.log('ü§ñ Chamando GPT-4 Vision API...')
    const visionAnalysis = await analyzeImageWithGPT4Vision(image, openaiApiKey)
    console.log('‚úÖ An√°lise visual conclu√≠da. Tamanho:', visionAnalysis.length, 'caracteres')
    console.log('üìù Primeiros 300 caracteres:', visionAnalysis.substring(0, 300))

    // Validar qualidade da an√°lise (menos restritivo)
    if (visionAnalysis.length < 50) {
      console.warn('‚ö†Ô∏è ALERTA: An√°lise muito curta!')
      throw new Error('An√°lise inv√°lida - resposta muito curta')
    }

    // 2. Extrair √¢ncoras da an√°lise
    const anchors = extractAnchorsFromAnalysis(visionAnalysis)
    console.log('üéØ √Çncoras extra√≠das:', anchors)

    if (anchors.length === 0 || (anchors.length === 1 && anchors[0] === 'pessoa')) {
      console.warn('‚ö†Ô∏è ALERTA: √Çncoras muito gen√©ricas!')
    }

    // 3. Gerar mensagem contextual baseada na an√°lise
    console.log('üí¨ Gerando mensagem contextual...')
    const message = await generateContextualMessage(visionAnalysis, anchors, tone, openaiApiKey)
    console.log('‚úÖ Mensagem gerada:', message)

    const processingTime = Date.now() - startTime
    console.log(`‚è±Ô∏è Tempo total de processamento: ${processingTime}ms`)

    // Return result
    return new Response(
      JSON.stringify({
        success: true,
        suggestion: message,
        anchors: anchors,
        visionAnalysis: visionAnalysis,
        processingTime: processingTime,
        confidence: 0.92,
        anchorCount: anchors.length,
        debug: {
          analysisLength: visionAnalysis.length,
          anchorCount: anchors.length,
          modelUsed: 'gpt-4o-mini'
        }
      }),
      {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        status: 200,
      }
    )

  } catch (error) {
    console.error('‚ùå Erro completo:', error)
    console.error('‚ùå Stack trace:', error.stack)
    return new Response(
      JSON.stringify({
        success: false,
        error: error.message,
        errorStack: error.stack,
        suggestion: 'Que foto interessante! Me conta mais sobre voc√™?',
        anchors: ['foto', 'momento'],
        visionAnalysis: 'Erro ao analisar imagem. Por favor, tente novamente.',
        processingTime: 0,
        confidence: 0.5,
        anchorCount: 2
      }),
      {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        status: 200, // Return 200 even on error to show fallback
      }
    )
  }
})

/**
 * Analisa imagem usando GPT-4 Vision com fallback inteligente
 */
async function analyzeImageWithGPT4Vision(imageBase64: string, apiKey: string): Promise<string> {
  console.log('üì° Iniciando an√°lise de imagem com IA...')
  
  // Lista de modelos para tentar com diferentes estrat√©gias
  const models = [
    { name: 'gpt-4o-mini', supportsVision: true, detail: 'high', maxTokens: 800 },
    { name: 'gpt-4o-mini', supportsVision: true, detail: 'low', maxTokens: 600 },
    { name: 'gpt-4o', supportsVision: true, detail: 'high', maxTokens: 1000 },
    { name: 'gpt-4-turbo', supportsVision: true, detail: 'high', maxTokens: 800 }
  ]

  let lastError = null

  // Tentar cada modelo at√© um funcionar
  for (const model of models) {
    try {
      console.log(`üîÑ Tentando modelo: ${model.name}`)
      
      if (model.supportsVision) {
        // Modelos com suporte a vis√£o
        const response = await fetch('https://api.openai.com/v1/chat/completions', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${apiKey}`
          },
          body: JSON.stringify({
            model: model.name,
            messages: [
              {
                role: 'system',
                content: `Voc√™ √© um SUPER ANALISTA ESPECIALIZADO em descrever imagens para apps de namoro.

SUA MISS√ÉO:
- Analisar MINUCIOSAMENTE cada detalhe da imagem
- Descrever EXATAMENTE o que v√™, sem inventar
- Ser ESPEC√çFICO e DETALHADO em cada aspecto
- Identificar elementos que tornam a foto √∫nica

VOC√ä √â EXPERT EM:
- Identificar pessoas, animais, objetos
- Descrever ambientes e cen√°rios
- Captar emo√ß√µes e express√µes
- Notar detalhes de vestimenta e acess√≥rios
- Reconhecer cores, padr√µes e texturas
- Entender o contexto e atmosfera da foto`
              },
              {
                role: 'user',
                content: [
                  {
                    type: 'text',
                    text: `Analise esta imagem como um SUPER ANALISTA e descreva MINUCIOSAMENTE:

üë• PESSOAS/ANIMAIS (se houver):
   - Quantas pessoas/animais
   - Caracter√≠sticas f√≠sicas vis√≠veis
   - Express√µes faciais e linguagem corporal
   - Cabelo: cor, estilo, comprimento
   - Roupa: tipo, cor, estilo
   - Acess√≥rios: √≥culos, joias, chap√©us, etc

üèôÔ∏è AMBIENTE:
   - Tipo de local (casa, rua, praia, carro, etc)
   - Interno ou externo
   - Ilumina√ß√£o (natural, artificial, dia, noite)
   - Objetos e m√≥veis vis√≠veis
   - Decora√ß√£o e elementos ao fundo

üé® CORES E EST√âTICA:
   - Cores predominantes
   - Padr√µes e estampas
   - Estilo geral da foto
   - Qualidade da imagem

üé≠ CONTEXTO E ATMOSFERA:
   - O que est√° acontecendo na foto
   - Atividade sendo realizada
   - Clima/vibe da imagem
   - Elementos que chamam aten√ß√£o

‚ö° DETALHES ESPECIAIS:
   - Qualquer coisa √∫nica ou interessante
   - Elementos que contam uma hist√≥ria
   - Aspectos que tornam a foto memor√°vel

EXEMPLO DE AN√ÅLISE BOA:
"A imagem mostra um gato cinza de pelagem uniforme deitado confortavelmente em uma cadeira estilo mid-century com estofado rosa claro. O gato tem olhos verdes e est√° em posi√ß√£o relaxada. Sobre a cadeira h√° um cobertor infantil colorido com estampa de dinossauros em tons de verde, laranja e azul. Ao fundo, v√™-se uma mesa branca com uma almofada personalizada escrita 'M√£e', um porta-pinceis vermelho e alguns objetos decorativos. O ambiente √© interno, bem iluminado com luz natural, com piso de cer√¢mica bege. A atmosfera √© aconchegante e caseira."

AGORA ANALISE ESTA IMAGEM COM O MESMO N√çVEL DE DETALHE:`
                  },
                  {
                    type: 'image_url',
                    image_url: {
                      url: `data:image/jpeg;base64,${imageBase64}`,
                      detail: model.detail
                    }
                  }
                ]
              }
            ],
            max_tokens: model.maxTokens,
            temperature: 0.4
          })
        })

        if (response.ok) {
          const data = await response.json()
          const analysis = data.choices[0].message.content
          console.log(`‚úÖ An√°lise bem-sucedida com ${model.name}:`, analysis)
          
          // Validar qualidade da an√°lise
          if (analysis.length > 80 && 
              !analysis.includes('n√£o consigo') && 
              !analysis.includes('n√£o posso') &&
              !analysis.includes('desculpe')) {
            console.log(`‚úÖ An√°lise v√°lida de ${model.name}`)
            return analysis
          } else {
            console.warn(`‚ö†Ô∏è An√°lise insuficiente de ${model.name} (${analysis.length} chars), tentando pr√≥ximo`)
            continue
          }
        }

        const errorData = await response.json()
        lastError = errorData.error?.message || 'Unknown error'
        console.warn(`‚ö†Ô∏è Modelo ${model.name} falhou:`, lastError)
      }

    } catch (error) {
      console.error(`‚ùå Erro ao tentar ${model.name}:`, error)
      lastError = error.message
      continue
    }
  }

  // Se todos os modelos falharam, lan√ßar erro para tentar fallback
  console.error('‚ùå Todos os modelos falharam.')
  console.error('‚ùå √öltimo erro:', lastError)
  throw new Error(`Todos os modelos de vis√£o falharam: ${lastError}`)
}

/**
 * Extrai √¢ncoras (palavras-chave) da an√°lise visual
 */
function extractAnchorsFromAnalysis(analysis: string): string[] {
  console.log('üîç Extraindo √¢ncoras da an√°lise...')
  console.log('üìù An√°lise recebida:', analysis.substring(0, 300))
  
  const keywords: string[] = []
  
  // Lista expandida de palavras relevantes
  const relevantWords = [
    // Animais
    'cachorro', 'gato', 'pet', 'animal', 'felino', 'canino',
    // Pessoas
    'mulher', 'homem', 'pessoa', 'sorriso', 'sorrindo', 'feliz', 'alegre',
    // Lugares
    'praia', 'mar', 'parque', 'cidade', 'montanha', 'casa', 'quarto', 'carro', 've√≠culo',
    // Objetos
    'guitarra', 'viol√£o', 'livro', 'caf√©', 'bicicleta', 'moto', 'bola', '√≥culos',
    'cadeira', 'sof√°', 'mesa', 'cobertor', 'almofada', 'quadro',
    // Cores
    'rosa', 'azul', 'verde', 'vermelho', 'amarelo', 'cinza', 'branco', 'preto',
    // Padr√µes
    'dinossauro', 'flor', 'listrado', 'estampado',
    // Atividades
    'tocando', 'lendo', 'correndo', 'caminhando', 'jogando', 'cozinhando', 'deitado', 'relaxando',
    // Ambientes
    'sol', 'c√©u', '√°rvore', 'flores', '√°gua', 'areia', 'grama', 'interno', 'externo',
    // Emo√ß√µes
    'felicidade', 'alegria', 'tranquilidade', 'energia', 'calmo', 'relaxado'
  ]
  
  const lowerAnalysis = analysis.toLowerCase()
  
  // Extrair palavras relevantes
  for (const word of relevantWords) {
    if (lowerAnalysis.includes(word)) {
      keywords.push(word)
    }
  }
  
  console.log('üéØ Palavras-chave encontradas:', keywords)
  
  // Se n√£o encontrou palavras espec√≠ficas, extrair substantivos importantes
  if (keywords.length < 2) {
    console.warn('‚ö†Ô∏è Poucas √¢ncoras encontradas, extraindo substantivos...')
    
    // Extrair palavras maiores que 4 letras que n√£o sejam comuns
    const commonWords = ['est√°', 'essa', 'esse', 'para', 'com', 'uma', 'foto', 'imagem', 'perfil', 'mostrando']
    const words = analysis.toLowerCase()
      .replace(/[.,!?;:()]/g, '')
      .split(/\s+/)
      .filter(w => w.length > 4 && !commonWords.includes(w))
      .slice(0, 8)
    
    console.log('üìö Substantivos extra√≠dos:', words)
    keywords.push(...words)
  }
  
  // Remover duplicatas e limitar
  const uniqueKeywords = [...new Set(keywords)].slice(0, 6)
  
  console.log('‚úÖ √Çncoras finais:', uniqueKeywords)
  return uniqueKeywords.length > 0 ? uniqueKeywords : ['foto', 'momento']
}

/**
 * Gera mensagem contextual usando GPT-4 baseado na an√°lise visual
 */
async function generateContextualMessage(
  visionAnalysis: string,
  anchors: string[],
  tone: string,
  apiKey: string
): Promise<string> {
  console.log('üí¨ Gerando mensagem contextual...')
  
  const toneInstructions = {
    'descontra√≠do': 'Tom leve, natural e espont√¢neo. Como um amigo puxando papo.',
    'flertar': 'Tom sedutor mas respeitoso. Charmoso e interessado romanticamente.',
    'amig√°vel': 'Tom acolhedor e gentil. Interessado genuinamente na pessoa.',
    'profissional': 'Tom respeitoso e admirador. Educado e intelectual.'
  }
  
  const instruction = toneInstructions[tone as keyof typeof toneInstructions] || toneInstructions['descontra√≠do']
  
  // Tentar gpt-4o-mini primeiro (mais acess√≠vel)
  const models = ['gpt-4o-mini', 'gpt-4o', 'gpt-4-turbo']
  
  for (const model of models) {
    try {
      const response = await fetch('https://api.openai.com/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${apiKey}`
        },
        body: JSON.stringify({
          model: model,
          messages: [
            {
              role: 'system',
              content: `Voc√™ √© um especialista em criar mensagens de abertura para apps de namoro brasileiros.

REGRAS IMPORTANTES:
1. Use APENAS informa√ß√µes da an√°lise visual fornecida
2. Seja ESPEC√çFICO sobre o que viu na foto
3. M√°ximo 2 frases curtas
4. SEMPRE termine com uma pergunta
5. ${instruction}
6. Use portugu√™s brasileiro natural
7. N√ÉO invente informa√ß√µes que n√£o est√£o na an√°lise`
            },
            {
              role: 'user',
              content: `AN√ÅLISE DA FOTO:
${visionAnalysis}

ELEMENTOS PRINCIPAIS: ${anchors.slice(0, 3).join(', ')}

TOM: ${tone}

Crie UMA mensagem de abertura que mencione algo ESPEC√çFICO que voc√™ viu na an√°lise acima:`
            }
          ],
          max_tokens: 100,
          temperature: 0.7
        })
      })

      if (response.ok) {
        const data = await response.json()
        const message = data.choices[0].message.content.trim()
        console.log(`‚úÖ Mensagem gerada com ${model}:`, message)
        return message
      }
      
      console.warn(`‚ö†Ô∏è Modelo ${model} falhou, tentando pr√≥ximo...`)
    } catch (error) {
      console.error(`‚ùå Erro com ${model}:`, error)
      continue
    }
  }
  
  // Fallback se todos falharem
  return `Adorei sua foto! Voc√™ parece ser uma pessoa muito interessante. Me conta mais sobre voc√™?`
}
