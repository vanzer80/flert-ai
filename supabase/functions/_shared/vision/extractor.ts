// src/vision/extractor.ts
// Extrator determin√≠stico de contexto visual usando GPT-4o Vision

import { VisionContextSchema, validateVisionContext, formatValidationErrors } from './schema.ts';

export interface VisionInput {
  imageUrl?: string;
  imageBase64?: string;
  ocrTextRaw?: string;
}

export interface VisionContext {
  schema_version: string;
  detected_persons: {
    count: number;
  };
  objects: Array<{
    name: string;
    confidence: number;
    source: string;
  }>;
  actions: Array<{
    name: string;
    confidence: number;
    source: string;
  }>;
  places: Array<{
    name: string;
    confidence: number;
    source: string;
  }>;
  colors: string[];
  ocr_text: string;
  notable_details: string[];
  confidence_overall: number;
}

export interface VisionExtractorResult {
  success: boolean;
  data?: VisionContext;
  low_confidence?: boolean;
  error?: string;
  attempts: number;
}

/**
 * Extrai contexto visual determin√≠stico de uma imagem usando GPT-4o Vision
 */
export async function extractVisionContext(input: VisionInput): Promise<VisionExtractorResult> {
  const { imageUrl, imageBase64, ocrTextRaw } = input;

  // Validar input
  if (!imageUrl && !imageBase64) {
    return {
      success: false,
      error: 'imageUrl ou imageBase64 √© obrigat√≥rio',
      attempts: 0
    };
  }

  const openaiApiKey = Deno.env.get('OPENAI_API_KEY');
  if (!openaiApiKey) {
    return {
      success: false,
      error: 'OpenAI API key n√£o configurada',
      attempts: 0
    };
  }

  // Preparar URL da imagem
  let imageUrlFinal = '';
  if (imageBase64) {
    imageUrlFinal = `data:image/jpeg;base64,${imageBase64}`;
  } else if (imageUrl) {
    imageUrlFinal = imageUrl;
  }

  const systemPrompt = `Voc√™ √© um extrator de CONTEXTO VISUAL e TEXTO de uma imagem.

REGRAS:
- Descreva APENAS o que est√° VIS√çVEL/LEG√çVEL.
- N√ÉO infira profiss√£o, emo√ß√µes, rela√ß√£o, local exato ou prefer√™ncias.
- Se houver texto, transcreva de forma normalizada em "ocr_text".
- Sa√≠da OBRIGATORIAMENTE em JSON, no esquema especificado, sem coment√°rios, sem texto extra.
- "confidence_overall" ‚àà [0.0,1.0].
- Em cada item {objects, actions, places} inclua "name" (min√∫sculo) e "confidence". Use "source":"vision".
- Se um campo n√£o tiver dados, use vazio (ex.: [] ou ""), NUNCA invente.

SCHEMA JSON:
{
  "schema_version": "1.0",
  "detected_persons": { "count": 0 },
  "objects": [ { "name": "cat", "confidence": 0.92, "source": "vision" } ],
  "actions": [ { "name": "cleaning", "confidence": 0.71, "source": "vision" } ],
  "places":  [ { "name": "kitchen",  "confidence": 0.78, "source": "vision" } ],
  "colors": ["pink","beige"],
  "ocr_text": "texto normalizado (ou vazio)",
  "notable_details": ["cadeira rosa","tecido com dinossauros com 'OMG'"],
  "confidence_overall": 0.0
}`;

  const userPrompt = `Analise esta imagem e extraia informa√ß√µes visuais seguindo exatamente o schema JSON especificado acima.

INSTRU√á√ïES:
- Liste apenas elementos claramente vis√≠veis na imagem
- Para texto, transcreva exatamente o que conseguir ler (normalize caracteres especiais)
- Para objetos, a√ß√µes e lugares: use nomes simples em min√∫sculo, apenas o que for √≥bvio
- Para cores: liste apenas cores dominantes claramente identific√°veis
- Para detalhes not√°veis: mencione elementos √∫nicos mas vis√≠veis (ex: padr√µes, texturas, objetos espec√≠ficos)
- Se n√£o conseguir identificar algo com confian√ßa, deixe o campo vazio ou com baixa confidence
- N√ÉO adicione elementos que n√£o est√£o na imagem`;

  const messages = [
    {
      role: 'system' as const,
      content: systemPrompt
    },
    {
      role: 'user' as const,
      content: [
        { type: 'text' as const, text: userPrompt },
        { type: 'image_url' as const, image_url: { url: imageUrlFinal, detail: 'high' } }
      ]
    }
  ];

  let attempts = 0;
  const maxAttempts = 2;

  while (attempts < maxAttempts) {
    attempts++;

    try {
      console.log(`üîç Tentativa ${attempts} de extra√ß√£o de vis√£o...`);

      const response = await fetch('https://api.openai.com/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${openaiApiKey}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: 'gpt-4o',
          messages,
          max_tokens: 800, // Conservador para garantir JSON completo
          temperature: 0.0, // Determin√≠stico
          response_format: { type: "json_object" }
        }),
      });

      if (!response.ok) {
        const errorText = await response.text();
        console.error(`OpenAI API error (${response.status}):`, errorText);

        if (attempts === maxAttempts) {
          return {
            success: false,
            error: `OpenAI API error: ${response.status}`,
            attempts
          };
        }
        continue;
      }

      const data = await response.json();
      const content = data.choices[0]?.message?.content || '';

      if (!content.trim()) {
        if (attempts === maxAttempts) {
          return {
            success: false,
            error: 'Resposta vazia da OpenAI',
            attempts
          };
        }
        continue;
      }

      // Tentar fazer parse do JSON
      let visionData: VisionContext;
      try {
        visionData = JSON.parse(content);
      } catch (parseError) {
        console.error('Erro ao fazer parse do JSON:', parseError);
        console.log('Resposta bruta:', content);

        if (attempts === maxAttempts) {
          return {
            success: false,
            error: 'JSON inv√°lido retornado pela OpenAI',
            attempts
          };
        }
        continue;
      }

      // Validar com Zod
      const validation = validateVisionContext(visionData);
      if (!validation.success) {
        console.error('Erro de valida√ß√£o Zod:', formatValidationErrors(validation.errors!));

        if (attempts === maxAttempts) {
          return {
            success: false,
            error: 'Dados n√£o correspondem ao schema esperado',
            attempts
          };
        }
        continue;
      }

      const validatedData = validation.data!;

      console.log(`‚úÖ Extra√ß√£o de vis√£o bem-sucedida em ${attempts} tentativa(s)`);
      console.log(`üìä Confian√ßa geral: ${validatedData.confidence_overall.toFixed(2)}`);
      console.log(`üéØ Objetos: ${validatedData.objects.length}, Cores: ${validatedData.colors.length}`);

      return {
        success: true,
        data: validatedData,
        attempts
      };

    } catch (error) {
      console.error(`Erro na tentativa ${attempts}:`, error);

      if (attempts === maxAttempts) {
        return {
          success: false,
          error: `Erro interno: ${error instanceof Error ? error.message : String(error)}`,
          attempts
        };
      }
    }
  }

  // Fallback para baixa confian√ßa se todas as tentativas falharam
  return {
    success: true,
    data: {
      schema_version: '1.0',
      detected_persons: { count: 0 },
      objects: [],
      actions: [],
      places: [],
      colors: [],
      ocr_text: '',
      notable_details: [],
      confidence_overall: 0.1 // Baixa confian√ßa
    },
    low_confidence: true,
    attempts: maxAttempts
  };
}
