import { serve } from "https://deno.land/std@0.168.0/http/server.ts"
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2'

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
  'Access-Control-Allow-Methods': 'POST, OPTIONS',
}

// Cliente admin para acessar cultural_references (Service Role Key)
const supabaseAdmin = createClient(
  Deno.env.get('SUPABASE_URL') ?? '',
  Deno.env.get('SUPABASE_SERVICE_ROLE_KEY') ?? '',
  {
    auth: {
      autoRefreshToken: false,
      persistSession: false
    }
  }
)

interface AnalysisRequest {
  image_path?: string
  image_base64?: string
  tone: string
  focus?: string
  user_id?: string
  text?: string
}

interface OpenAIMessage {
  role: 'system' | 'user' | 'assistant'
  content: string | Array<{
    type: 'text' | 'image_url'
    text?: string
    image_url?: {
      url: string
      detail?: 'low' | 'high' | 'auto'
    }
  }>
}

serve(async (req) => {
  // Handle CORS preflight requests
  if (req.method === 'OPTIONS') {
    return new Response('ok', { headers: corsHeaders })
  }

  try {
    // Initialize Supabase client
    const supabaseClient = createClient(
      Deno.env.get('SUPABASE_URL') ?? '',
      Deno.env.get('SUPABASE_ANON_KEY') ?? '',
      {
        global: {
          headers: { Authorization: req.headers.get('Authorization')! },
        },
      }
    )

    // Parse request body
    const { image_path, image_base64, tone, focus, user_id, text }: AnalysisRequest = await req.json()

    // Validate required fields
    if (!tone) {
      return new Response(
        JSON.stringify({ error: 'Tone is required' }),
        { 
          status: 400, 
          headers: { ...corsHeaders, 'Content-Type': 'application/json' } 
        }
      )
    }

    // Check daily usage limit if user_id is provided
    if (user_id) {
      const { data: canUse, error: limitError } = await supabaseClient
        .rpc('check_daily_limit', { user_id })

      if (limitError) {
        console.error('Error checking daily limit:', limitError)
      } else if (!canUse) {
        return new Response(
          JSON.stringify({ 
            error: 'Daily limit reached',
            code: 'DAILY_LIMIT_EXCEEDED'
          }),
          { 
            status: 429, 
            headers: { ...corsHeaders, 'Content-Type': 'application/json' } 
          }
        )
      }
    }

    // Prepare OpenAI API call
    const openaiApiKey = Deno.env.get('OPENAI_API_KEY')
    if (!openaiApiKey) {
      throw new Error('OpenAI API key not configured')
    }

    // Extract detailed image information including person's name
    let imageDescription = 'Nenhuma imagem fornecida'
    let personName = 'Nenhum'

    if (image_base64 || image_path) {
      let imageUrl = ''
      
      if (image_base64) {
        imageUrl = `data:image/jpeg;base64,${image_base64}`
      } else if (image_path) {
        // If image_path is an absolute URL, use it directly. Otherwise, treat as storage path.
        const isAbsoluteUrl = /^https?:\/\//i.test(image_path)
        if (isAbsoluteUrl) {
          imageUrl = image_path
        } else {
          // Get public URL from Supabase Storage bucket 'images'
          const { data } = supabaseClient.storage
            .from('images')
            .getPublicUrl(image_path)
          imageUrl = data.publicUrl
        }
      }

      if (imageUrl) {
        // Step 1: Extract detailed information from image using GPT-4o Vision
        const visionPrompt = `Analise esta imagem de perfil em detalhes e retorne as informa√ß√µes no seguinte formato JSON:
{
  "nome_da_pessoa_detectado": "[Nome da pessoa se vis√≠vel na imagem, caso contr√°rio 'Nenhum']",
  "descricao_visual": "[Descri√ß√£o detalhada da apar√™ncia, vestu√°rio, cen√°rio, express√£o, objetos vis√≠veis]",
  "texto_extraido_ocr": "[Qualquer texto vis√≠vel na imagem: nome de usu√°rio, legendas, placas, camisetas]"
}

Foque especialmente em:
- Identificar o NOME da pessoa se estiver vis√≠vel (em username, legenda, texto na imagem)
- Apar√™ncia f√≠sica e estilo
- Cen√°rio e ambiente
- Objetos que indiquem hobbies ou interesses
- Qualquer texto vis√≠vel na imagem`

        const visionMessages: OpenAIMessage[] = [
          {
            role: 'user',
            content: [
              { type: 'text', text: visionPrompt },
              { type: 'image_url', image_url: { url: imageUrl, detail: 'high' } }
            ]
          }
        ]

        try {
          const visionResponse = await fetch('https://api.openai.com/v1/chat/completions', {
            method: 'POST',
            headers: {
              'Authorization': `Bearer ${openaiApiKey}`,
              'Content-Type': 'application/json',
            },
            body: JSON.stringify({
              model: 'gpt-4o',
              messages: visionMessages,
              max_tokens: 500,
              temperature: 0.3,
            }),
          })

          if (visionResponse.ok) {
            const visionData = await visionResponse.json()
            const visionResult = visionData.choices[0]?.message?.content || ''
            
            // Try to parse JSON response
            try {
              const parsedVision = JSON.parse(visionResult)
              personName = parsedVision.nome_da_pessoa_detectado || 'Nenhum'
              const visualDesc = parsedVision.descricao_visual || ''
              const ocrText = parsedVision.texto_extraido_ocr || ''
              imageDescription = `Descri√ß√£o Visual: ${visualDesc}\n\nTexto Extra√≠do (OCR): ${ocrText}`
            } catch {
              // If JSON parsing fails, use the raw response
              imageDescription = visionResult
              // Try to extract name from the response text
              const nameMatch = visionResult.match(/nome[:\s]+([\w\s]+)/i)
              if (nameMatch) {
                personName = nameMatch[1].trim()
              }
            }
          }
        } catch (visionError) {
          console.error('Vision API error:', visionError)
          // Fallback to basic description
          imageDescription = 'Imagem de perfil fornecida, mas n√£o foi poss√≠vel extrair informa√ß√µes detalhadas.'
        }
      }
    }

    // Add additional text context if provided
    if (text && text.trim().length > 0) {
      imageDescription += `\n\nContexto adicional de texto/bio: ${text}`
    }

    // NEW: Buscar refer√™ncias culturais brasileiras
    const region = await getUserRegion(user_id) // Detecta regi√£o do usu√°rio (ou 'nacional')
    const culturalRefs = await getCulturalReferences(tone, region, 3)
    
    // Build system prompt with extracted information + cultural references
    const systemPrompt = buildEnrichedSystemPrompt(tone, focus, imageDescription, personName, culturalRefs)

    // Prepare messages for OpenAI
    const messages: OpenAIMessage[] = [
      {
        role: 'system',
        content: systemPrompt
      },
      {
        role: 'user',
        content: 'Gere 3 sugest√µes de mensagens criativas e envolventes seguindo todas as instru√ß√µes do sistema, utilizando as informa√ß√µes da imagem e o nome da pessoa se dispon√≠vel.'
      }
    ]

    // Call OpenAI API
    const openaiResponse = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${openaiApiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: image_base64 || image_path ? 'gpt-4o' : 'gpt-4o-mini',
        messages,
        max_tokens: 500,
        temperature: 0.8,
      }),
    })

    if (!openaiResponse.ok) {
      const errorText = await openaiResponse.text()
      console.error('OpenAI API error:', openaiResponse.status, errorText)
      return new Response(
        JSON.stringify({
          error: 'OPENAI_ERROR',
          httpStatus: openaiResponse.status,
          details: errorText,
        }),
        { status: 502, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      )
    }

    const openaiData = await openaiResponse.json()
    const aiResponse = openaiData.choices[0]?.message?.content || ''

    // Parse suggestions from AI response
    const suggestions = parseSuggestions(aiResponse)

    // Save conversation and suggestions to database if user_id is provided
    let conversationId = null
    if (user_id) {
      try {
        // Save conversation
        const { data: conversation, error: convError } = await supabaseClient
          .from('conversations')
          .insert({
            user_id,
            image_url: image_path || null,
            analysis_result: {
              tone,
              focus,
              ai_response: aiResponse,
              suggestions,
              timestamp: new Date().toISOString()
            }
          })
          .select()
          .single()

        if (convError) {
          console.error('Error saving conversation:', convError)
        } else {
          conversationId = conversation.id

          // Save individual suggestions
          const suggestionInserts = suggestions.map(suggestion => ({
            conversation_id: conversationId,
            tone_type: tone,
            suggestion_text: suggestion
          }))

          const { error: sugError } = await supabaseClient
            .from('suggestions')
            .insert(suggestionInserts)

          if (sugError) {
            console.error('Error saving suggestions:', sugError)
          }

          // Increment daily usage
          await supabaseClient.rpc('increment_daily_usage', { user_id })
        }
      } catch (dbError) {
        console.error('Database error:', dbError)
        // Continue execution even if database save fails
      }
    }

    // Return successful response
    const response = {
      success: true,
      suggestions,
      conversation_id: conversationId,
      tone,
      focus,
      usage_info: {
        model_used: image_base64 || image_path ? 'gpt-4o' : 'gpt-4o-mini',
        tokens_used: openaiData.usage?.total_tokens || 0
      }
    }

    return new Response(
      JSON.stringify(response),
      { 
        headers: { ...corsHeaders, 'Content-Type': 'application/json' } 
      }
    )

  } catch (error) {
    console.error('Function error:', error)
    
    return new Response(
      JSON.stringify({ 
        error: 'Internal server error',
        message: (error as Error).message 
      }),
      { 
        status: 500, 
        headers: { ...corsHeaders, 'Content-Type': 'application/json' } 
      }
    )
  }
})

/**
 * Busca refer√™ncias culturais relevantes para o contexto
 */
async function getCulturalReferences(
  tone: string,
  region: string = 'nacional',
  count: number = 3
): Promise<any[]> {
  try {
    const references = []

    // Determinar tipos relevantes baseado no tom
    const types = getCulturalTypesForTone(tone)

    // Buscar refer√™ncias de cada tipo
    for (const type of types) {
      const { data, error } = await supabaseAdmin
        .rpc('get_random_cultural_reference', {
          reference_type: type,
          reference_region: region
        })

      if (data && data.length > 0) {
        references.push(data[0])
      }
      
      if (references.length >= count) break
    }

    return references.slice(0, count)
  } catch (error) {
    console.error('Error fetching cultural references:', error)
    return []
  }
}

/**
 * Mapeia tom para tipos de refer√™ncias culturais apropriadas
 */
function getCulturalTypesForTone(tone: string): string[] {
  const toneNormalized = tone.toLowerCase()

  const toneTypeMap: Record<string, string[]> = {
    'flertar': ['giria', 'musica', 'expressao_regional'],
    'descontra√≠do': ['giria', 'meme', 'comida'],
    'casual': ['giria', 'meme', 'lugar'],
    'genu√≠no': ['musica', 'novela', 'personalidade'],
    'sensual': ['musica', 'giria', 'meme']
  }

  // Encontrar tipos baseado no tom (com fallback)
  for (const [key, types] of Object.entries(toneTypeMap)) {
    if (toneNormalized.includes(key)) {
      return types
    }
  }

  return ['giria', 'meme']  // Default
}

/**
 * Detecta regi√£o do usu√°rio baseado em perfil ou localiza√ß√£o
 */
async function getUserRegion(userId: string | undefined): Promise<string> {
  if (!userId) return 'nacional'

  try {
    const { data, error } = await supabaseAdmin
      .from('profiles')
      .select('region')
      .eq('id', userId)
      .single()

    if (data && data.region) {
      return data.region
    }
  } catch (error) {
    console.error('Error fetching user region:', error)
  }

  return 'nacional'  // Fallback
}

/**
 * Constr√≥i system prompt enriquecido com cultura brasileira
 */
function buildEnrichedSystemPrompt(
  tone: string, 
  focus: string | undefined, 
  imageDescription: string, 
  personName: string,
  culturalRefs: any[]
): string {
  // Base prompt (vers√£o existente)
  let prompt = buildSystemPrompt(tone, focus, imageDescription, personName)

  // Adicionar contexto cultural se dispon√≠vel
  if (culturalRefs.length > 0) {
    prompt += `\n\n**REFER√äNCIAS CULTURAIS BRASILEIRAS:**\n`
    prompt += `Use estas refer√™ncias de forma natural e contextualizada:\n\n`

    culturalRefs.forEach((ref, index) => {
      prompt += `${index + 1}. **${ref.termo}** (${ref.tipo})\n`
      prompt += `   - Significado: ${ref.significado}\n`
      prompt += `   - Exemplo: "${ref.exemplo_uso}"\n`
      prompt += `   - Contexto: ${ref.contexto_flerte}\n\n`
    })

    prompt += `**INSTRU√á√ïES DE USO:**\n`
    prompt += `- Incorpore naturalmente (n√£o force)\n`
    prompt += `- Use 1-2 refer√™ncias por sugest√£o (m√°ximo)\n`
    prompt += `- Adapte ao contexto da conversa\n`
    prompt += `- Mantenha autenticidade brasileira\n`
    prompt += `- Considere a regi√£o se relevante\n`
  }

  return prompt
}

function buildSystemPrompt(tone: string, focus: string | undefined, imageDescription: string, personName: string): string {
  const toneInstructions = getToneInstructions(tone)
  const hasTone = tone && tone.toLowerCase() !== 'nenhum'
  const hasFocus = focus && focus.toLowerCase() !== 'nenhum'
  const hasName = personName && personName.toLowerCase() !== 'nenhum'
  
  const toneSection = hasTone 
    ? `**Tom Escolhido pelo Usu√°rio:** ${tone}\n${toneInstructions}\n` 
    : `**Tom Escolhido pelo Usu√°rio:** Nenhum (use tom descontra√≠do e casual por padr√£o)\n`
  
  const focusSection = hasFocus 
    ? `**Foco Escolhido pelo Usu√°rio:** ${focus}\n` 
    : `**Foco Escolhido pelo Usu√°rio:** Nenhum\n`
  
  const nameSection = hasName
    ? `**Nome da Pessoa Detectado:** ${personName}\n`
    : `**Nome da Pessoa Detectado:** Nenhum\n`
  
  return `Voc√™ √© o FlertAI, um cupido digital super observador e com um talento nato para criar mensagens de paquera aut√™nticas e irresist√≠veis, focadas no mercado brasileiro. Sua miss√£o √© ajudar as pessoas a quebrar o gelo e iniciar conversas genu√≠nas, como se um amigo pr√≥ximo e divertido estivesse dando uma forcinha.

Sua tarefa √© analisar a imagem de perfil fornecida com olhos de √°guia, extraindo cada detalhe visual e textual que possa inspirar uma conex√£o. Use essas observa√ß√µes para criar mensagens de paquera personalizadas, criativas e que soem 100% humanas.

**Informa√ß√µes Fornecidas:**
- **Descri√ß√£o Detalhada da Imagem:** ${imageDescription}
${nameSection}${toneSection}${focusSection}
**Elementos Visuais e Contextuais a Analisar Detalhadamente:**
- **Apar√™ncia da Pessoa:** Idade aparente, estilo (cl√°ssico, moderno, alternativo), caracter√≠sticas marcantes (cabelo, olhos, sorriso)
- **Vestu√°rio e Acess√≥rios:** Tipo de roupa, se h√° marcas, acess√≥rios (√≥culos, joias, chap√©us) que revelem personalidade ou status
- **Cen√°rio e Ambiente:** Local (praia, montanha, cidade, caf√©, casa), tipo de ilumina√ß√£o, objetos de fundo que indiquem hobbies, viagens, estilo de vida (livros, instrumentos musicais, animais de estima√ß√£o, obras de arte)
- **Express√£o e Linguagem Corporal:** Sorriso (aberto, misterioso), postura, olhar, que transmitam confian√ßa, alegria, serenidade
- **Textos na Imagem:** Qualquer texto vis√≠vel (placas, camisetas, legendas) que possa ser usado para contextualizar
- **Qualidade da Imagem:** Se a foto √© profissional, casual, divertida, etc.

**Instru√ß√µes para a Cria√ß√£o das Mensagens:**
- **Seja um Cupido Moderno:** Sua voz deve ser amig√°vel, um pouco atrevida (se o tom permitir), e sempre positiva. Pense como algu√©m que realmente quer ver a pessoa feliz
- **Portugu√™s Brasileiro Aut√™ntico:** Use g√≠rias e express√µes comuns no Brasil, de forma natural e n√£o for√ßada. Evite formalidades excessivas
- **ORIGINALIDADE √© a Chave:** Fuja de clich√™s! A mensagem deve ser √∫nica e mostrar que voc√™ realmente "viu" a pessoa na foto. Nada de "oi linda" ou "tudo bem?"
- **Priorize Tom, Foco e Nome:**
${hasName ? `    - **USO DO NOME (PRIORIDADE ALTA):** Utilize o nome "${personName}" de forma natural e amig√°vel em pelo menos uma das mensagens. Ex: "Oi, ${personName}! Adorei seu perfil..." ou "${personName}, seu sorriso ilumina mais que qualquer p√¥r do sol!"\n` : ''}${hasTone ? '    - APLIQUE RIGOROSAMENTE as instru√ß√µes de tom fornecidas acima\n' : ''}${hasFocus ? `    - INTEGRE O FOCO "${focus}" de forma criativa e natural em pelo menos uma das mensagens, conectando-o com os elementos visuais da imagem\n` : ''}${!hasTone && !hasFocus && !hasName ? '    - **Cen√°rio de Fallback:** Gere as mensagens com um tom descontra√≠do e casual, utilizando os elementos mais proeminentes da imagem para contextualiza√ß√£o, como se voc√™ estivesse fazendo uma observa√ß√£o inteligente e espont√¢nea\n' : ''}- **Conex√£o Genu√≠na:** A mensagem deve criar uma ponte entre o que voc√™ observou na imagem e um poss√≠vel interesse ou elogio. Se a pessoa est√° na praia, n√£o diga apenas "gostei da praia", mas "Essa praia parece incr√≠vel! Me deu uma vontade de te chamar pra um mergulho por l√°... üòâ"
- **Uso de Emojis:** Use emojis de forma sutil e estrat√©gica para adicionar emo√ß√£o e personalidade, mas sem exageros. Escolha emojis que complementem o tom da mensagem
- **Respeito Acima de Tudo:** Mesmo em tons sensuais, a mensagem deve ser respeitosa e convidar √† intera√ß√£o, nunca ser invasiva ou objetificante
- **Tamanho e Fluidez:** As sugest√µes devem ter entre 20 e 40 palavras, permitindo mais naturalidade e criatividade, sem serem excessivamente longas
- **Gere exatamente 3 sugest√µes numeradas**

**Formato de Sa√≠da Obrigat√≥rio:**
1. [Mensagem criativa e contextualizada, com emoji]
2. [Mensagem criativa e contextualizada, com emoji]
3. [Mensagem criativa e contextualizada, com emoji]`
}

function getToneInstructions(tone: string): string {
  const normalizedTone = tone.toLowerCase().trim()
  
  const toneMap: { [key: string]: string } = {
    'üòò flertar': `**Instru√ß√µes de Tom:** Flertante e rom√¢ntico, demonstrando interesse amoroso de forma sutil e charmosa. Use palavras como "encantador(a)", "olhar", "sorriso", "conex√£o". Emojis sugeridos: üòâ‚ú®üíñ`,
    'flertar': `**Instru√ß√µes de Tom:** Flertante e rom√¢ntico, demonstrando interesse amoroso de forma sutil e charmosa. Use palavras como "encantador(a)", "olhar", "sorriso", "conex√£o". Emojis sugeridos: üòâ‚ú®üíñ`,
    'üòè descontra√≠do': `**Instru√ß√µes de Tom:** Casual e divertido, com um toque de humor e leveza. Use express√µes como "que vibe", "curti", "top". Emojis sugeridos: üòÇüòé‚úåÔ∏è`,
    'descontra√≠do': `**Instru√ß√µes de Tom:** Casual e divertido, com um toque de humor e leveza. Use express√µes como "que vibe", "curti", "top". Emojis sugeridos: üòÇüòé‚úåÔ∏è`,
    'üòé casual': `**Instru√ß√µes de Tom:** Natural e espont√¢neo, como uma conversa entre amigos. Foque em observa√ß√µes simples e convites abertos. Emojis sugeridos: üëãüòäüí¨`,
    'casual': `**Instru√ß√µes de Tom:** Natural e espont√¢neo, como uma conversa entre amigos. Foque em observa√ß√µes simples e convites abertos. Emojis sugeridos: üëãüòäüí¨`,
    'üí¨ genu√≠no': `**Instru√ß√µes de Tom:** Aut√™ntico e profundo, mostrando interesse real na pessoa e em seus hobbies/paix√µes. Use palavras como "interessante", "curiosidade", "apaixonado(a)". Emojis sugeridos: ü§îüí°‚ù§Ô∏è`,
    'genu√≠no': `**Instru√ß√µes de Tom:** Aut√™ntico e profundo, mostrando interesse real na pessoa e em seus hobbies/paix√µes. Use palavras como "interessante", "curiosidade", "apaixonado(a)". Emojis sugeridos: ü§îüí°‚ù§Ô∏è`,
    'üòà sensual': `**Instru√ß√µes de Tom:** Picante e sedutor, com um toque de sensualidade respeitosa e confiante. Use palavras como "irresist√≠vel", "provocante", "qu√≠mica". Emojis sugeridos: üî•üòàüòè`,
    'sensual': `**Instru√ß√µes de Tom:** Picante e sedutor, com um toque de sensualidade respeitosa e confiante. Use palavras como "irresist√≠vel", "provocante", "qu√≠mica". Emojis sugeridos: üî•üòàüòè`,
    'nenhum': ''
  }
  
  return toneMap[normalizedTone] || `**Instru√ß√µes de Tom:** Use um tom descontra√≠do e casual por padr√£o, adaptando-se aos elementos visuais da imagem. Emojis sugeridos: üòä‚ú®üëã`
}

function parseSuggestions(content: string): string[] {
  const suggestions: string[] = []
  const lines = content.split('\n')
  
  for (const line of lines) {
    const trimmed = line.trim()
    if (trimmed && /^\d+\./.test(trimmed)) {
      // Remove the number and dot from the beginning
      const suggestion = trimmed.replace(/^\d+\.\s*/, '')
      if (suggestion) {
        suggestions.push(suggestion)
      }
    }
  }
  
  // If parsing failed, try to extract any meaningful content
  if (suggestions.length === 0 && content.trim()) {
    // Split by common separators and take first 3 meaningful parts
    const parts = content.split(/[.!?]/).filter(part => part.trim().length > 10)
    suggestions.push(...parts.slice(0, 3).map(part => part.trim()))
  }
  
  // Ensure we have at least some suggestions
  if (suggestions.length === 0) {
    suggestions.push(
      'Que foto incr√≠vel! Me conta mais sobre essa aventura',
      'Adorei seu estilo, voc√™ tem um sorriso contagiante',
      'Essa imagem me deixou curioso para te conhecer melhor'
    )
  }
  
  return suggestions.slice(0, 3) // Ensure max 3 suggestions
}
